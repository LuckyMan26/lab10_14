{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2ab2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luckyman/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2025-04-15 20:05:06.068975: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744736706.236828     871 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744736706.284532     871 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 20:05:06.844698: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\").to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b36f6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=1, dropout=0.1):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout if num_layers > 1 else 0)\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Improved classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #h0 = torch.zeros(x.size(0), self.num_layers, self.hidden_size).to(x.device)\n",
    "        #c0 = torch.zeros(x.size(0), self.num_layers,  self.hidden_size).to(x.device)\n",
    "        #print(\"h0:\", h0.shape)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        #print(\"lstm_out:\", lstm_out.shape)\n",
    "        final_hidden_state = lstm_out.reshape(lstm_out.size(0), lstm_out.size(1))\n",
    "        print(\"final_hidden_state:\", final_hidden_state.shape)\n",
    "        print(\"layer_norm:\", self.hidden_size)\n",
    "        #print(\"final_hidden_state:\", final_hidden_state.shape)\n",
    "        pooled = self.layer_norm(final_hidden_state)\n",
    "        pooled = self.dropout(pooled)\n",
    "\n",
    "        # Classifier head\n",
    "        out = self.classifier(pooled)\n",
    "        #print(\"out:\", pooled.shape)\n",
    "        return self.output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4e439642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup\n",
    "vocab_size = 10000\n",
    "embedding_dim = 384\n",
    "hidden_dim = 64\n",
    "output_dim = 3  # For binary classification\n",
    "sequence_length = 100\n",
    "\n",
    "model = LSTMClassifier(vocab_size=vocab_size, embedding_dim=embedding_dim,hidden_dim = hidden_dim, output_dim= output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4bda84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6743e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6c3b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27481/27481 [03:52<00:00, 118.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Make sure tqdm is used for pandas apply\n",
    "tqdm.pandas()\n",
    "\n",
    "df['embeddings'] = df['text'].progress_apply(lambda x: embedding_model.encode(str(x), convert_to_tensor=True).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcceaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a DataFrame `df` and your features are X and target variable is y\n",
    "X = df.drop(columns=['sentiment'])  # Features (remove the target column)\n",
    "y = df['sentiment']  # Target variable (e.g., sentiment)\n",
    "\n",
    "# Split the data: 80% for training and 20% for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train['embeddings']\n",
    "y_train = y_train.apply(lambda x: 2 if x == 'positive' else 1 if x == 'neutral' else 0)\n",
    "\n",
    "X_val = X_val['embeddings']\n",
    "y_val = y_val.apply(lambda x: 2 if x == 'positive' else 1 if x == 'neutral' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b67a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09670f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4815a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X_val_array = np.array(X_val.tolist())\n",
    "X_val = torch.tensor(X_val_array, dtype=torch.float32).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94097ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.float32).type(torch.LongTensor)\n",
    "y_val_array = np.array(y_val.tolist())\n",
    "\n",
    "y_val = torch.tensor(y_val_array, dtype=torch.float32).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffcebe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3895e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_one_hot(labels, num_classes):\n",
    "    one_hot_vectors = np.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot_vectors[i, label] = 1\n",
    "    return one_hot_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e5e159c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_hidden_state: torch.Size([32, 64])\n",
      "layer_norm: 32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[32], expected input with shape [*, 32], but got input of size[32, 64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m batch_x, batch_y \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device), batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#print(f\"Outputs: {outputs}\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[112], line 39\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_norm:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#print(\"final_hidden_state:\", final_hidden_state.shape)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m pooled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_hidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m pooled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Classifier head\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2900\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2892\u001b[0m         layer_norm,\n\u001b[1;32m   2893\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2898\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2899\u001b[0m     )\n\u001b[0;32m-> 2900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given normalized_shape=[32], expected input with shape [*, 32], but got input of size[32, 64]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Dataset & DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset((X_val), (y_val))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = LSTMClassifier(vocab_size=vocab_size, embedding_dim=embedding_dim,hidden_dim = 32, output_dim = output_dim, num_layers=1, dropout=0.3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        #print(f\"Outputs: {outputs}\")\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation loop\n",
    "    val_losses = []\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for val_x, val_y in val_loader:\n",
    "            val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "            outputs = model(val_x).float()\n",
    "            loss = criterion(outputs, val_y)\n",
    "            val_losses.append(loss.item())\n",
    "            #val_labels.extend(val_y.cpu().numpy())\n",
    "\n",
    "    one_hot = np.zeros(3)\n",
    "    val_labels = labels_to_one_hot(val_labels, 3)\n",
    "    #val_acc = accuracy_score(val_labels, (val_preds))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {sum(train_losses)/len(train_losses):.4f} - Val loss: {sum(val_losses)/len(val_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "914823f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv('test.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef7b7daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3534/3534 [00:28<00:00, 122.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Make sure tqdm is used for pandas apply\n",
    "tqdm.pandas()\n",
    "\n",
    "df_test['embeddings'] = df_test['text'].progress_apply(lambda x: embedding_model.encode(str(x), convert_to_tensor=True).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c26cb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a DataFrame `df` and your features are X and target variable is y\n",
    "X_test = df_test.drop(columns=['sentiment'])  # Features (remove the target column)\n",
    "y_test = df_test['sentiment']  # Target variable (e.g., sentiment)\n",
    "\n",
    "X_test = X_test['embeddings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb38e147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        neutral\n",
       "1       positive\n",
       "2       negative\n",
       "3       positive\n",
       "4       positive\n",
       "          ...   \n",
       "3529    negative\n",
       "3530    positive\n",
       "3531    negative\n",
       "3532    positive\n",
       "3533    positive\n",
       "Name: sentiment, Length: 3534, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8c97b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_lengths = len(X_test.values)*[384]\n",
    "\n",
    "# Create a tensor with an extra dimension\n",
    "data = np.array([row for row in X_test.values])\n",
    "X_tensor = torch.tensor(data, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d2e1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.apply(lambda x: 2 if x == 'positive' else 1 if x == 'neutral' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ad8d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b186030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset((X_tensor), (y_tensor_test))\n",
    "\n",
    "test_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for val_x, val_y in test_loader:\n",
    "        val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "        outputs = model(val_x).float()\n",
    "        #print(f\"Outputs: {outputs}\")\n",
    "        preds = []\n",
    "        for output in outputs:\n",
    "            pred = torch.argmax(output).cpu().numpy()\n",
    "            pred_array = np.zeros(3)\n",
    "            pred_array[pred] = 1\n",
    "            preds.append(pred_array)\n",
    "            #print(f\"Preds: {preds}\")\n",
    "        preds = torch.tensor(preds)\n",
    "        #print(f\"Preds: {preds}\")\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(val_y.cpu().numpy())\n",
    "\n",
    "one_hot = np.zeros(3)\n",
    "val_labels = labels_to_one_hot(test_labels, 3)\n",
    "val_acc = accuracy_score(val_labels, (test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee0f0c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6949245042750591\n"
     ]
    }
   ],
   "source": [
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_871/1970833847.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"lstm.pth\", map_location='cuda'))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTMClassifier:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([128, 384]) from checkpoint, the shape in current model is torch.Size([256, 384]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layer_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([16, 32]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for classifier.3.weight: copying a param with shape torch.Size([3, 16]) from checkpoint, the shape in current model is torch.Size([3, 32]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlstm.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTMClassifier:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([128, 384]) from checkpoint, the shape in current model is torch.Size([256, 384]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layer_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([16, 32]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for classifier.3.weight: copying a param with shape torch.Size([3, 16]) from checkpoint, the shape in current model is torch.Size([3, 32])."
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(vocab_size=vocab_size, embedding_dim=embedding_dim,hidden_dim = 32, output_dim = output_dim, num_layers=1, dropout=0.3)\n",
    "\n",
    "model.load_state_dict(torch.load(\"lstm.pth\", map_location='cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6f4522a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_hidden_state: torch.Size([1, 64])\n",
      "layer_norm: 64\n",
      "Predicted class: [2]\n"
     ]
    }
   ],
   "source": [
    "s = \"I bought this car yesterday\"\n",
    "embeddings   = embedding_model.encode(s, convert_to_tensor=True).unsqueeze(0).to('cpu')\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(embeddings)\n",
    "    pred = torch.argmax(output, dim=1).cpu().numpy()\n",
    "    print(f\"Predicted class: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "397f2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstm.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
